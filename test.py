# from langchain import HuggingFaceHub
# from langchain.experimental.llms import JsonFormer
from langchain import LLMChain, PromptTemplate
# from transformers import pipeline
from langchain.llms import OpenAI
from langchain.output_parsers import ResponseSchema, StructuredOutputParser

# hf_model = pipeline(
#     "text-generation", model="cerebras/Cerebras-GPT-590M", max_new_tokens=200
# )

# js=JsonFormer(json_schema={"score":{"type":"number"},"prompt":{"type":"string"}},pipeline=hf_model)

# query = "Write a blog on elon musk  "

prompt_template = """

You need to analyze the given prompt {query} and provide a score on the scale of 1 to 100 based on the following parameters:. 
    The given prompt should be clear and specific, using complete sentences. The prompt might have  provide context.. 
    The prompt might have  system and user instructions .\n4. The prompt might  have explicit cues.. The prompt should be  broken down for  complex tasks 
    or limit the scope.Now, generate a new_prompt that satisfies all the parameters,
    """


from langchain.llms import HuggingFaceHub
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

repo_id = "cerebras/Cerebras-GPT-590M"

llm = HuggingFaceHub(
    repo_id=repo_id,
    model_kwargs={"temperature": 0.5, "max_length": 250},
    huggingfacehub_api_token="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",
)


class PromptAnalysis(BaseModel):
    score: str = Field(description="score of the promprt in percentage")
    new_prompt: str = Field(description="new prompt generated by the model")


query = "write a blog on elon musk"

parser = PydanticOutputParser(pydantic_object=PromptAnalysis)

prompt = PromptTemplate(
    template="Answer the user query.\n{format_instructions}\n{query}\n",
    input_variables=["query"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

_input = prompt.format_prompt(query=query)

output = llm(_input.to_string())

x = parser.parse(output)

print(x)
